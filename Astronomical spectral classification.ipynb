{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install pandas\n",
    "# !unzip data_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = np.load('data_numpy/0.npy')\n",
    "labels = np.load('data_numpy/lb_0.npy', allow_pickle=True)\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    b = np.load('data_numpy/'+str(i)+'.npy')\n",
    "    chunk = np.concatenate((chunk, b), axis = 0)\n",
    "    del b\n",
    "    b = np.load('data_numpy/lb_'+str(i)+'.npy', allow_pickle=True)\n",
    "    labels = np.concatenate((labels, b), axis = 0)\n",
    "    del b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {'star': 0, 'qso': 1, 'galaxy': 2}\n",
    "labels = np.array([mydict[key] for key in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = np.load('data_numpy/6.npy')\n",
    "valid_lbl = np.load('data_numpy/lb_6.npy', allow_pickle=True)\n",
    "valid_lbl = np.array([mydict[key] for key in valid_lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = np.log(1.0*(chunk>=0)*chunk+1) - 1.0*np.log(-1.0*(1.0*(chunk<0)*chunk-1))\n",
    "valid = np.log(1.0*(valid>=0)*valid+1) - 1.0*np.log(-1.0*(1.0*(valid<0)*valid-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(chunk, axis=0)\n",
    "std = np.std(chunk, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_mean.npy', mean)\n",
    "np.save('all_std.npy', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.load('all_mean.npy')\n",
    "std = np.load('all_std.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = (chunk-mean)/std\n",
    "valid = (valid-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPModel, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.fc1 = nn.Linear(2600, 1000)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(1000)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm1d(500)\n",
    "        \n",
    "        self.fc3 = nn.Linear(500, 100)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm1d(100)\n",
    "        \n",
    "        self.fc4 = nn.Linear(100, 50)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm1d(50)\n",
    "        \n",
    "        self.fc5 = nn.Linear(50, 3)\n",
    "        # self.logsoftmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.relu1(self.fc1(x)))\n",
    "        x = self.bn2(self.relu1(self.fc2(x)))\n",
    "        x = self.bn3(self.relu3(self.fc3(x)))\n",
    "        x = self.bn4(self.relu4(self.fc4(x)))\n",
    "        x = self.fc5(x)\n",
    "        # x = self.logsoftmax(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel()\n",
    "model.to(device);\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.999), eps=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    tensor(116.7611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8881, device='cuda:0')\n",
      "1    tensor(86.6275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9085, device='cuda:0')\n",
      "2    tensor(74.2898, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2045, device='cuda:0')\n",
      "3    tensor(66.2443, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6329, device='cuda:0')\n",
      "4    tensor(59.9163, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5791, device='cuda:0')\n",
      "5    tensor(55.5518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6680, device='cuda:0')\n",
      "6    tensor(52.3829, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7440, device='cuda:0')\n",
      "7    tensor(50.0778, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5911, device='cuda:0')\n",
      "8    tensor(48.5570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6510, device='cuda:0')\n",
      "9    tensor(45.5650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7255, device='cuda:0')\n",
      "10    tensor(43.8377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5783, device='cuda:0')\n",
      "11    tensor(44.3290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8186, device='cuda:0')\n",
      "12    tensor(44.8788, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1594, device='cuda:0')\n",
      "13    tensor(43.0668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7076, device='cuda:0')\n",
      "14    tensor(45.6772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7367, device='cuda:0')\n",
      "15    tensor(45.5850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6790, device='cuda:0')\n",
      "16    tensor(43.2253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5492, device='cuda:0')\n",
      "17    tensor(42.3628, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9257, device='cuda:0')\n",
      "18    tensor(40.1837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7484, device='cuda:0')\n",
      "19    tensor(38.6021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5584, device='cuda:0')\n",
      "20    tensor(37.7206, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.0570, device='cuda:0')\n",
      "21    tensor(36.8719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7499, device='cuda:0')\n",
      "22    tensor(35.7117, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0397, device='cuda:0')\n",
      "23    tensor(35.8451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6609, device='cuda:0')\n",
      "24    tensor(34.9041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6086, device='cuda:0')\n",
      "25    tensor(34.0774, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7235, device='cuda:0')\n",
      "26    tensor(34.3499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8621, device='cuda:0')\n",
      "27    tensor(33.3945, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3252, device='cuda:0')\n",
      "28    tensor(31.2530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6069, device='cuda:0')\n",
      "29    tensor(31.2626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5858, device='cuda:0')\n",
      "30    tensor(32.2101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6524, device='cuda:0')\n",
      "31    tensor(29.9626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5657, device='cuda:0')\n",
      "32    tensor(30.2363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5905, device='cuda:0')\n",
      "33    tensor(29.7112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5152, device='cuda:0')\n",
      "34    tensor(28.0460, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0639, device='cuda:0')\n",
      "35    tensor(27.6539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9957, device='cuda:0')\n",
      "36    tensor(26.9009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6089, device='cuda:0')\n",
      "37    tensor(28.1873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5207, device='cuda:0')\n",
      "38    tensor(28.7298, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6004, device='cuda:0')\n",
      "39    tensor(28.3442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8555, device='cuda:0')\n",
      "40    tensor(27.6091, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.1327, device='cuda:0')\n",
      "41    tensor(27.1859, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9940, device='cuda:0')\n",
      "42    tensor(25.5429, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0414, device='cuda:0')\n",
      "43    tensor(24.4942, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8041, device='cuda:0')\n",
      "44    tensor(24.1375, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3802, device='cuda:0')\n",
      "tensor(27.0470, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_list = []\n",
    "val_list = []\n",
    "min_val = 100000\n",
    "weight = torch.tensor([0.1, 2, 0.8])\n",
    "weight = weight.to(device, dtype=torch.float32)\n",
    "for ep in range(500):\n",
    "    tot_loss = 0\n",
    "    model.train()\n",
    "    for i in range(0, len(labels), 500):\n",
    "        old_dict = model.state_dict()\n",
    "        data = chunk[i:i+500]\n",
    "        lbs = labels[i:i+500]\n",
    "        \n",
    "        data = torch.from_numpy(data.astype('float32'))\n",
    "        data = data.to(device, dtype=torch.float32)\n",
    "        lbs = torch.from_numpy(lbs)\n",
    "        lbs = lbs.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        del data\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(output, lbs, weight)\n",
    "        tot_loss = tot_loss + loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del lbs\n",
    "        del output\n",
    "\n",
    "    valid_loss = 0\n",
    "    model.eval()\n",
    "    for i in range(0, len(valid), 500):\n",
    "        data = valid[i:i+500]\n",
    "        lbs = valid_lbl[i:i+500]\n",
    "\n",
    "        data = torch.from_numpy(data.astype('float32'))\n",
    "        data = data.to(device, dtype=torch.float32)\n",
    "        lbs = torch.from_numpy(lbs)\n",
    "        lbs = lbs.to(device)\n",
    "        output = model(data)\n",
    "        output = torch.argmax(output, axis=1)\n",
    "        wgt = 1.0*lbs; wgt[wgt==0] = 0.1;wgt[wgt==1] = 2;wgt[wgt==2] = 1\n",
    "        error = torch.sum(wgt*(output-lbs)*(output-lbs))/1000\n",
    "        # loss = F.cross_entropy(output, lbs, weight)\n",
    "        del data, lbs, output\n",
    "        valid_loss = valid_loss + error\n",
    "    val_list.append(valid_loss)\n",
    "    \n",
    "    if valid_loss < min_val:\n",
    "        torch.save(model.state_dict(), \"models/best_4\")\n",
    "        min_val = 1.0*valid_loss\n",
    "    # print(valid_loss)\n",
    "\n",
    "\n",
    "    if len(loss_list)>10:\n",
    "        ave = sum(loss_list[-10:])/10\n",
    "        if tot_loss > ave:\n",
    "            loss_list.append(tot_loss)\n",
    "            print(tot_loss)\n",
    "            model.load_state_dict(old_dict)\n",
    "            break\n",
    "    \n",
    "\n",
    "    loss_list.append(tot_loss)\n",
    "    print(ep, \"  \", tot_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= np.load('test.npy')\n",
    "test_lbl = np.load('test_lbl.npy', allow_pickle=True)\n",
    "test_lbl = np.array([mydict[key] for key in test_lbl])\n",
    "test = np.log(1.0*(test>=0)*test+1) - 1.0*np.log(-1.0*(1.0*(test<0)*test-1))\n",
    "test = (test-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gaga = model.state_dict()\n",
    "model.load_state_dict(torch.load('models/best_4'))\n",
    "# model.load_state_dict(gaga)\n",
    "model.eval()\n",
    "glist = []\n",
    "aa = []; bb = []; cc = [];\n",
    "for i in range(0, len(test), 500):\n",
    "    data = test[i:i+500]\n",
    "    lbs = test_lbl[i:i+500]\n",
    "\n",
    "    data = torch.from_numpy(data.astype('float32'))\n",
    "    data = data.to(device, dtype=torch.float32)\n",
    "    lbs = torch.from_numpy(lbs)\n",
    "    lbs = lbs.to(device)\n",
    "    # weight = torch.tensor([0.2, 1, 1])\n",
    "    # weight = weight.to(device, dtype=torch.float32)\n",
    "\n",
    "    output = model(data)\n",
    "    glist.append(torch.sum(torch.argmax(output, axis=1) == lbs))\n",
    "    # print(torch.sum(torch.argmax(output, axis=1) == lbs))\n",
    "    aa.append(torch.sum(torch.argmax(output, axis=1)[lbs==1] == 1)*100/torch.sum(lbs==1))\n",
    "    bb.append(torch.sum(torch.argmax(output, axis=1)[lbs==2] == 2)*100/torch.sum(lbs==2))\n",
    "    cc.append(torch.sum(torch.argmax(output, axis=1)[lbs==0] == 0)*100/torch.sum(lbs==0))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(97.2275, device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(glist)/len(glist)*1/5\n",
    "# sum(cc)/len(aa)\n",
    "# len(glist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(483, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
       "         0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "         2, 0, 0, 1, 0, 2, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "         2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0,\n",
       "         0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0,\n",
       "         0, 1, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 0, 0,\n",
       "         0, 0, 2, 2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2,\n",
       "         0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "        device='cuda:0'),\n",
       " tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
       "         0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "         2, 0, 0, 0, 0, 2, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "         2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0,\n",
       "         0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0,\n",
       "         1, 1, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 0, 0,\n",
       "         0, 0, 2, 2, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2,\n",
       "         0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.sum(torch.argmax(output, axis=1) == lbs))\n",
    "torch.argmax(output, axis=1), lbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(98.3254, device='cuda:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.argmax(output, axis=1)[lbs==1] == 1)*100/torch.sum(lbs==1)\n",
    "torch.sum(torch.argmax(output, axis=1)[lbs==2] == 2)*100/torch.sum(lbs==2)\n",
    "torch.sum(torch.argmax(output, axis=1)[lbs==0] == 0)*100/torch.sum(lbs==0)\n",
    "# torch.argmax(output, axis=1)[lbs==2]\n",
    "# torch.argmax(output, axis=1)[lbs==1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
